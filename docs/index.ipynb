{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \n",
        "\n",
        "# Welcome!\n",
        "\n",
        "This is a course about Bayesian statistics, targeted at systems\n",
        "biologists.\n",
        "\n",
        "There are three intended learning outcomes:\n",
        "\n",
        "1.  Understand the theoretical basis for applying Bayesian data analysis\n",
        "    to practical scientific problems\n",
        "\n",
        "2.  Develop a familiarity with implementing Bayesian data analysis using\n",
        "    modern software tools\n",
        "\n",
        "3.  Gain deep understanding of both theory and practice of elements of\n",
        "    Bayesian data analysis that are particularly relevant to\n",
        "    computational biology, including custom hierarchical models, large\n",
        "    analyses and statistical models with embedded ODE systems.\n",
        "\n",
        "## General format\n",
        "\n",
        "Each week we have a one-hour seminar. The goal is to spend the time\n",
        "approximately as follows:\n",
        "\n",
        "1.  25-35mins on ‘theory’, aka learning things from the book and getting\n",
        "    more reading material\n",
        "\n",
        "2.  25-35mins on practical computer work\n",
        "\n",
        "## Plan\n",
        "\n",
        "### Week 1: [What is Bayesian inference?](introduction_to_bayesian_inference.md)\n",
        "\n",
        "#### Theory\n",
        "\n",
        "Statistical inference in general\n",
        "\n",
        "Bayesian statistical inference\n",
        "\n",
        "The big challenge: dimensionality\n",
        "\n",
        "#### Practice\n",
        "\n",
        "Set up development environment\n",
        "\n",
        "git basics\n",
        "\n",
        "Install Stan and cmdstanpy\n",
        "\n",
        "#### Reading\n",
        "\n",
        "Jaynes (2003, Ch. 1)\n",
        "\n",
        "Laplace (1986)\n",
        "\n",
        "Box and Tiao (1992, Ch. 1.1)\n",
        "\n",
        "### Week 2: [MCMC and Stan](mcmc_and_stan.md)\n",
        "\n",
        "#### Theory\n",
        "\n",
        "What is MCMC?\n",
        "\n",
        "Hamiltonian Monte Carlo\n",
        "\n",
        "Probabilistic programming\n",
        "\n",
        "#### Practice\n",
        "\n",
        "Run an MCMC algorithm and inspect the results\n",
        "\n",
        "#### Reading\n",
        "\n",
        "Betancourt (2018)\n",
        "\n",
        "### Week 3: [Metropolis-Hastings](metropolis-hastings.qmd)\n",
        "\n",
        "### Week 4: [After MCMC](after_mcmc.md): diagnostics, and decisions\n",
        "\n",
        "#### Theory\n",
        "\n",
        "Diagnostics: convergence, divergent transitions, effective sample size\n",
        "\n",
        "Model evaluation as decision theory\n",
        "\n",
        "Why negative log likelihood is a good default loss function\n",
        "\n",
        "#### Practice\n",
        "\n",
        "Diagnose some good and bad MCMC runs\n",
        "\n",
        "#### Reading\n",
        "\n",
        "Vehtari et al. (2021)\n",
        "\n",
        "Vehtari, Gelman, and Gabry (2017)\n",
        "\n",
        "### Week 5: Regression models in biology\n",
        "\n",
        "#### Theory\n",
        "\n",
        "Generalised linear models\n",
        "\n",
        "Prior elicitation\n",
        "\n",
        "Hierarchical models\n",
        "\n",
        "#### Practice\n",
        "\n",
        "Compare some statistical models of a simulated biological dataset\n",
        "\n",
        "#### Reading\n",
        "\n",
        "Betancourt (2024)\n",
        "\n",
        "### Week 6: Hierarchical models\n",
        "\n",
        "### Week 7: ODEs\n",
        "\n",
        "#### Theory\n",
        "\n",
        "What is an ODE?\n",
        "\n",
        "ODE solvers\n",
        "\n",
        "ODE solvers inside probabilistic programs\n",
        "\n",
        "#### Practice\n",
        "\n",
        "Fit a model with an ODE.\n",
        "\n",
        "#### Reading\n",
        "\n",
        "Timonen et al. (2022)\n",
        "\n",
        "### Week 8: Bayesian workflow\n",
        "\n",
        "#### Theory\n",
        "\n",
        "Parts of a statistical anlaysis (not just inference!)\n",
        "\n",
        "Why Bayesian workflow is complex: non-linearity and plurality\n",
        "\n",
        "Writing scalable statistical programming projects\n",
        "\n",
        "#### Practice\n",
        "\n",
        "Write a scalable statistical analysis with\n",
        "[bibat](https://docs.readthedocs.io/en/stable/config-file/v2.html).\n",
        "\n",
        "#### Reading\n",
        "\n",
        "Gelman et al. (2020)\n",
        "\n",
        "### Week 9-10: Project\n",
        "\n",
        "Format: one hour joint feedback and help session\n",
        "\n",
        "Betancourt, Michael. 2018. “A Conceptual Introduction to Hamiltonian\n",
        "Monte Carlo.” *arXiv:1701.02434 \\[Stat\\]*, July.\n",
        "<http://arxiv.org/abs/1701.02434>.\n",
        "\n",
        "———. 2024. “Hierarchical Modeling.”\n",
        "<https://betanalpha.github.io/assets/case_studies/hierarchical_modeling.html>.\n",
        "\n",
        "Box, George E. P., and George C. Tiao. 1992. “Bayesian Inference in\n",
        "Statistical Analysis.” A Wiley-Interscience Publication. New York:\n",
        "Wiley.\n",
        "<https://onlinelibrary-wiley-com.proxy.findit.cvt.dk/doi/epdf/10.1002/9781118033197>.\n",
        "\n",
        "Gelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C. Margossian, Bob\n",
        "Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian\n",
        "Bürkner, and Martin Modrák. 2020. “Bayesian Workflow.” *arXiv:2011.01808\n",
        "\\[Stat\\]*, November. <http://arxiv.org/abs/2011.01808>.\n",
        "\n",
        "Jaynes, E. T. 2003. “Probability Theory: The Logic of Science.” Edited\n",
        "by G. Larry Bretthorst. Cambridge, UK:\n",
        "<https://readyforai.com/download/probability-theory-the-logic-of-science-pdf/>;\n",
        "Cambridge University Press.\n",
        "\n",
        "Laplace, Pierre Simon. 1986. “Memoir on the Probability of the Causes of\n",
        "Events.” *Statistical Science* 1 (3).\n",
        "<https://doi.org/10.1214/ss/1177013621>.\n",
        "\n",
        "Timonen, Juho, Nikolas Siccha, Ben Bales, Harri Lähdesmäki, and Aki\n",
        "Vehtari. 2022. “An Importance Sampling Approach for Reliable and\n",
        "Efficient Inference in Bayesian Ordinary Differential Equation Models.”\n",
        "arXiv. <https://doi.org/10.48550/arXiv.2205.09059>.\n",
        "\n",
        "Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian\n",
        "Model Evaluation Using Leave-One-Out Cross-Validation and WAIC.”\n",
        "*Statistics and Computing* 27 (5): 1413–32.\n",
        "<https://doi.org/10.1007/s11222-016-9696-4>.\n",
        "\n",
        "Vehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, and\n",
        "Paul-Christian Bürkner. 2021. “Rank-Normalization, Folding, and\n",
        "Localization: An Improved R^ for Assessing Convergence of MCMC (with\n",
        "Discussion).” *Bayesian Analysis* 16 (2): 667–718.\n",
        "<https://doi.org/10.1214/20-BA1221>."
      ],
      "id": "cc04c912-5887-438d-b46b-d1ee2e70b7dd"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}